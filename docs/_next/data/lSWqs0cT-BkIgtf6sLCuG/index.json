{"pageProps":{"body":"<h1 id=\"multi-agent-system\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#multi-agent-system\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Multi-Agent System</h1>\n<h1 id=\"công-nghệ-tác-tử\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#công-nghệ-tác-tử\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Công nghệ tác tử</h1>\n<h2 id=\"chapter-1-key-notes\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#chapter-1-key-notes\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Chapter 1 key notes</h2>\n<ul>\n<li>Multi-agent system <p></p><div class=\"portal-container\">\n<div class=\"portal-head\">\n<div class=\"portal-backlink\">\n<div class=\"portal-title\">From <span class=\"portal-text-title\">C1-Introduction</span></div>\n<a href=\"/multi-agent-system/notes/nyjsbqpAPM3WrEtJJFLmn\" class=\"portal-arrow\">Go to text <span class=\"right-arrow\">→</span></a>\n</div>\n</div>\n<div id=\"portal-parent-anchor\" class=\"portal-parent\" markdown=\"1\">\n<div class=\"portal-parent-fader-top\"></div>\n<div class=\"portal-parent-fader-bottom\"></div><ul>\n<li>Consists of <strong>a number of agents</strong>\n<ul>\n<li>Each agent has different goal and motivation</li>\n<li>Ability to cooperate, coordinate, negotiate</li>\n</ul>\n</li>\n</ul>\n</div></div><p></p></li>\n</ul>\n<h2 id=\"chapter-2-key-notes\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#chapter-2-key-notes\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Chapter 2 key notes</h2>\n<ul>\n<li>\n<p>Agent ~ Autonomous ~ Making decisions</p>\n<ul>\n<li>What to perform?</li>\n<li>When to perform?</li>\n</ul>\n</li>\n<li>\n<p>Agents</p>\n<ul>\n<li>Have attitude\n<ul>\n<li>Autonomous</li>\n<li>Smart - flexible behaviours</li>\n<li>Active</li>\n</ul>\n</li>\n<li>Environment awareness</li>\n<li>Operate in a limited domain</li>\n</ul>\n</li>\n<li>\n<p></p><p></p><div class=\"portal-container\">\n<div class=\"portal-head\">\n<div class=\"portal-backlink\">\n<div class=\"portal-title\">From <span class=\"portal-text-title\">C2-IntelligentAgents</span></div>\n<a href=\"/multi-agent-system/notes/FlDl9gx2mBtFM41D123aX\" class=\"portal-arrow\">Go to text <span class=\"right-arrow\">→</span></a>\n</div>\n</div>\n<div id=\"portal-parent-anchor\" class=\"portal-parent\" markdown=\"1\">\n<div class=\"portal-parent-fader-top\"></div>\n<div class=\"portal-parent-fader-bottom\"></div><ul>\n<li>Observable: fully or partially\n<ul>\n<li>Fully: The agent can obtain complete, accurate, up-to-date information about the environment's state</li>\n</ul>\n</li>\n<li>Deterministic or non-deterministic\n<ul>\n<li>Deterministic: Any action has a single <strong>guaranteed effect</strong> (no uncertainty)</li>\n</ul>\n</li>\n<li>Static or dynamic\n<ul>\n<li>Static: Remain <strong>unchanged</strong> except by the agent's action</li>\n</ul>\n</li>\n<li>Discrete or continuous\n<ul>\n<li>Discrete: <strong>a fixed, finite number of actions</strong> and percepts in it</li>\n</ul>\n</li>\n<li>Episodic or non-episodic\n<ul>\n<li>Phân đoạn</li>\n<li>Episodic environment\n<ul>\n<li>The performance of agent is <strong>dependent on a number of discrete eptisodes</strong></li>\n<li>No linkages between different scenarios</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Real time\n<ul>\n<li><strong>Time</strong> plays a part in <strong>evaluating</strong> an agents performance</li>\n</ul>\n</li>\n</ul>\n</div></div><p></p><p></p>\n</li>\n<li>\n<p>Intelligent agents</p>\n<ul>\n<li>Reactive\n<ul>\n<li>Environment aware</li>\n<li>Responds to changes</li>\n</ul>\n</li>\n<li>Pro-active (achieving goals)</li>\n<li>Social ability (working with others)</li>\n</ul>\n</li>\n<li>\n<p>The behaviour of an agent can be predicted using its intention</p>\n</li>\n<li>\n<p>Abstract architecture</p>\n<ul>\n<li>World has a finite set of states</li>\n<li>Agents have a set of possible actions</li>\n<li>A run: a sequence of actions and states</li>\n</ul>\n</li>\n<li>\n<p>Notion</p>\n<ul>\n<li>Environment: states, initial states, transformer function</li>\n<li>Agent: runs -> action</li>\n<li>A system: \n<ul>\n<li>a pair of an agent &#x26; an environment</li>\n<li>has a set of possible runs</li>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-17-55-51.png\"> </li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Deliberative vs Purely reactive</p>\n<ul>\n<li>Deliberative: Making decisions Reactive agent\n<ul>\n<li>Always do the <strong>same thing</strong> in the <strong>same state</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p></p><p></p><div class=\"portal-container\">\n<div class=\"portal-head\">\n<div class=\"portal-backlink\">\n<div class=\"portal-title\">From <span class=\"portal-text-title\">C2-IntelligentAgents</span></div>\n<a href=\"/multi-agent-system/notes/FlDl9gx2mBtFM41D123aX\" class=\"portal-arrow\">Go to text <span class=\"right-arrow\">→</span></a>\n</div>\n</div>\n<div id=\"portal-parent-anchor\" class=\"portal-parent\" markdown=\"1\">\n<div class=\"portal-parent-fader-top\"></div>\n<div class=\"portal-parent-fader-bottom\"></div><ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-22-43-54.png\"></li>\n<li>Agent's internal <strong>data structure</strong>\n<ul>\n<li>Record information about the environment state &#x26; history</li>\n</ul>\n</li>\n<li><strong>See</strong>: observe the environment\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-22-44-54.png\"></li>\n<li>Output is a percept (nhận thức)</li>\n</ul>\n</li>\n<li><strong>Action</strong>: decision making\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-22-48-24.png\"></li>\n<li>Internal states -> actions</li>\n</ul>\n</li>\n<li><strong>Next</strong>: \n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-22-51-50.png\"></li>\n<li>Internal States + percept => new internal states</li>\n<li><strong>Updates</strong> the agent's view when it gets a <strong>new percept</strong></li>\n</ul>\n</li>\n</ul>\n</div></div><p></p><p></p>\n</li>\n<li>\n<p>Utility function:</p>\n<ul>\n<li>Rewarding agents</li>\n<li>Locality: utility for each state, no long term view</li>\n<li>Reinforcement: a discount for states later on</li>\n<li>Sequential decision making: Utilities depend on the route</li>\n<li>Assign utilities for runs: long term view</li>\n<li>Expected utility: run utility * run possibility</li>\n</ul>\n</li>\n<li>\n<p>Optimal agents</p>\n<ul>\n<li>Maximizes the expected utility (on average)</li>\n<li><strong>Bounded</strong>: only those agents that <strong>can be implemented on machine m</strong></li>\n</ul>\n</li>\n<li>\n<p>Task environment</p>\n<ul>\n<li>Predicate task specification: succeeds/fails</li>\n<li>A pair: environment, task specification\n<ul>\n<li>the system's properties</li>\n<li>judging criterias</li>\n</ul>\n</li>\n<li>Judging\n<ul>\n<li>Pessimistic: all run must be succeeded</li>\n<li>Optimistic: a run is succeeded</li>\n</ul>\n</li>\n<li>The probability of success\n<ul>\n<li>Sum of all success runs</li>\n</ul>\n</li>\n<li>Types\n<ul>\n<li>Achivement: to the goal</li>\n<li>Maintenance: not to fail</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"chapter-3-key-notes\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#chapter-3-key-notes\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Chapter 3 key notes</h2>\n<ul>\n<li>\n<p>Architecture: modules &#x26; interaction between them</p>\n</li>\n<li>\n<p>Symbolic Reasoning Agents: Modeling the world using symbols</p>\n</li>\n<li>\n<p>Deductive Reasoning Agents:</p>\n<ul>\n<li>Theorem proving</li>\n<li>Find a possible action by\n<ul>\n<li>Prove it works</li>\n<li>Prove NotDo(action) can not be proved</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Agent oriented programming: using the intentional notions</p>\n</li>\n</ul>\n<hr>\n<h2 id=\"children\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#children\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Children</h2>\n<ol>\n<li><a href=\"/multi-agent-system/notes/nyjsbqpAPM3WrEtJJFLmn\">C1-Introduction</a></li>\n<li><a href=\"/multi-agent-system/notes/FlDl9gx2mBtFM41D123aX\">C2-IntelligentAgents</a></li>\n<li><a href=\"/multi-agent-system/notes/GscZd6gucdQM8ZPOjmJnM\">C3-DeductiveReasoningAgents</a></li>\n</ol>","note":{"id":"BnuhRJcMOGIp7ASYnzgfK","title":"Multi-Agent System","vault":{"fsPath":"vault"},"type":"note","desc":"","links":[{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C1-Introduction","position":{"start":{"line":4,"column":22,"offset":64},"end":{"line":4,"column":66,"offset":108},"indent":[]},"xvault":false,"to":{"fname":"C1-Introduction","anchorHeader":"multi-agent-system,1:#*"}},{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C2-IntelligentAgents","position":{"start":{"line":19,"column":3,"offset":368},"end":{"line":19,"column":56,"offset":421},"indent":[]},"xvault":false,"to":{"fname":"C2-IntelligentAgents","anchorHeader":"environment-properties,1:#*"}},{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C2-IntelligentAgents","position":{"start":{"line":47,"column":3,"offset":1180},"end":{"line":47,"column":52,"offset":1229},"indent":[]},"xvault":false,"to":{"fname":"C2-IntelligentAgents","anchorHeader":"agents-with-states,1:#*"}}],"anchors":{"công-nghệ-tác-tử":{"type":"header","text":"Công nghệ tác tử","value":"công-nghệ-tác-tử","line":7,"column":0,"depth":1},"chapter-1-key-notes":{"type":"header","text":"Chapter 1 key notes","value":"chapter-1-key-notes","line":9,"column":0,"depth":2},"chapter-2-key-notes":{"type":"header","text":"Chapter 2 key notes","value":"chapter-2-key-notes","line":12,"column":0,"depth":2},"chapter-3-key-notes":{"type":"header","text":"Chapter 3 key notes","value":"chapter-3-key-notes","line":81,"column":0,"depth":2}},"fname":"root","updated":1639971779311,"created":1639839870130,"parent":null,"children":["nyjsbqpAPM3WrEtJJFLmn","FlDl9gx2mBtFM41D123aX","GscZd6gucdQM8ZPOjmJnM"],"data":{},"contentHash":"0bed781d8c55b3ab9beed855964a880b","custom":{"nav_order":0,"permalink":"/"},"body":"# Công nghệ tác tử\n\n## Chapter 1 key notes\n- Multi-agent system ![[C1-Introduction#multi-agent-system,1:#*]]\n\n## Chapter 2 key notes\n- Agent ~ Autonomous ~ Making decisions\n  - What to perform?\n  - When to perform?\n\n- Agents\n  - Have attitude\n    - Autonomous\n    - Smart - flexible behaviours\n    - Active\n  - Environment awareness\n  - Operate in a limited domain\n\n- ![[C2-IntelligentAgents#environment-properties,1:#*]]\n\n- Intelligent agents\n  - Reactive\n    - Environment aware\n    - Responds to changes\n  - Pro-active (achieving goals)\n  - Social ability (working with others)\n\n- The behaviour of an agent can be predicted using its intention\n\n- Abstract architecture\n  - World has a finite set of states\n  - Agents have a set of possible actions\n  - A run: a sequence of actions and states\n\n- Notion\n  - Environment: states, initial states, transformer function\n  - Agent: runs -> action\n  - A system: \n    - a pair of an agent & an environment\n    - has a set of possible runs\n    - ![](./assets/images/2021-12-19-17-55-51.png) \n\n- Deliberative vs Purely reactive\n  - Deliberative: Making decisions Reactive agent\n    - Always do the **same thing** in the **same state**\n\n- ![[C2-IntelligentAgents#agents-with-states,1:#*]]\n\n- Utility function:\n  - Rewarding agents\n  - Locality: utility for each state, no long term view\n  - Reinforcement: a discount for states later on\n  - Sequential decision making: Utilities depend on the route\n  - Assign utilities for runs: long term view\n  - Expected utility: run utility * run possibility\n\n- Optimal agents\n  - Maximizes the expected utility (on average)\n  - **Bounded**: only those agents that **can be implemented on machine m**\n\n- Task environment\n  - Predicate task specification: succeeds/fails\n  - A pair: environment, task specification\n    - the system's properties\n    - judging criterias\n  - Judging\n    - Pessimistic: all run must be succeeded\n    - Optimistic: a run is succeeded\n  - The probability of success\n    - Sum of all success runs\n  - Types\n    - Achivement: to the goal\n    - Maintenance: not to fail\n\n## Chapter 3 key notes\n\n- Architecture: modules & interaction between them\n\n- Symbolic Reasoning Agents: Modeling the world using symbols\n\n- Deductive Reasoning Agents:\n  - Theorem proving\n  - Find a possible action by\n    - Prove it works\n    - Prove NotDo(action) can not be proved\n\n- Agent oriented programming: using the intentional notions"},"config":{"version":4,"useFMTitle":true,"useNoteTitleForLink":true,"mermaid":true,"useKatex":true,"dev":{"enablePreviewV2":true},"site":{"copyAssets":true,"siteHierarchies":["root"],"siteRootDir":"docs","usePrettyRefs":true,"title":"Dendron","description":"Personal knowledge space","siteLastModified":true,"gh_edit_branch":"main","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"assetsPrefix":"/multi-agent-system","siteUrl":"https://thanhpp.github.io","usePrettyLinks":true,"siteNotesDir":"notes","siteFaviconPath":"favicon.ico","gh_edit_link":true,"gh_edit_link_text":"Edit this page on GitHub","gh_root":"docs/","gh_edit_view_mode":"edit","writeStubs":true,"siteIndex":"root"},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false}},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true}},"customHeadContent":null,"noteIndex":{"id":"BnuhRJcMOGIp7ASYnzgfK","title":"Multi-Agent System","vault":{"fsPath":"vault"},"type":"note","desc":"","links":[{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C1-Introduction","position":{"start":{"line":4,"column":22,"offset":64},"end":{"line":4,"column":66,"offset":108},"indent":[]},"xvault":false,"to":{"fname":"C1-Introduction","anchorHeader":"multi-agent-system,1:#*"}},{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C2-IntelligentAgents","position":{"start":{"line":19,"column":3,"offset":368},"end":{"line":19,"column":56,"offset":421},"indent":[]},"xvault":false,"to":{"fname":"C2-IntelligentAgents","anchorHeader":"environment-properties,1:#*"}},{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C2-IntelligentAgents","position":{"start":{"line":47,"column":3,"offset":1180},"end":{"line":47,"column":52,"offset":1229},"indent":[]},"xvault":false,"to":{"fname":"C2-IntelligentAgents","anchorHeader":"agents-with-states,1:#*"}}],"anchors":{"công-nghệ-tác-tử":{"type":"header","text":"Công nghệ tác tử","value":"công-nghệ-tác-tử","line":7,"column":0,"depth":1},"chapter-1-key-notes":{"type":"header","text":"Chapter 1 key notes","value":"chapter-1-key-notes","line":9,"column":0,"depth":2},"chapter-2-key-notes":{"type":"header","text":"Chapter 2 key notes","value":"chapter-2-key-notes","line":12,"column":0,"depth":2},"chapter-3-key-notes":{"type":"header","text":"Chapter 3 key notes","value":"chapter-3-key-notes","line":81,"column":0,"depth":2}},"fname":"root","updated":1639971779311,"created":1639839870130,"parent":null,"children":["nyjsbqpAPM3WrEtJJFLmn","FlDl9gx2mBtFM41D123aX","GscZd6gucdQM8ZPOjmJnM"],"data":{},"contentHash":"0bed781d8c55b3ab9beed855964a880b","custom":{"nav_order":0,"permalink":"/"},"body":"# Công nghệ tác tử\n\n## Chapter 1 key notes\n- Multi-agent system ![[C1-Introduction#multi-agent-system,1:#*]]\n\n## Chapter 2 key notes\n- Agent ~ Autonomous ~ Making decisions\n  - What to perform?\n  - When to perform?\n\n- Agents\n  - Have attitude\n    - Autonomous\n    - Smart - flexible behaviours\n    - Active\n  - Environment awareness\n  - Operate in a limited domain\n\n- ![[C2-IntelligentAgents#environment-properties,1:#*]]\n\n- Intelligent agents\n  - Reactive\n    - Environment aware\n    - Responds to changes\n  - Pro-active (achieving goals)\n  - Social ability (working with others)\n\n- The behaviour of an agent can be predicted using its intention\n\n- Abstract architecture\n  - World has a finite set of states\n  - Agents have a set of possible actions\n  - A run: a sequence of actions and states\n\n- Notion\n  - Environment: states, initial states, transformer function\n  - Agent: runs -> action\n  - A system: \n    - a pair of an agent & an environment\n    - has a set of possible runs\n    - ![](./assets/images/2021-12-19-17-55-51.png) \n\n- Deliberative vs Purely reactive\n  - Deliberative: Making decisions Reactive agent\n    - Always do the **same thing** in the **same state**\n\n- ![[C2-IntelligentAgents#agents-with-states,1:#*]]\n\n- Utility function:\n  - Rewarding agents\n  - Locality: utility for each state, no long term view\n  - Reinforcement: a discount for states later on\n  - Sequential decision making: Utilities depend on the route\n  - Assign utilities for runs: long term view\n  - Expected utility: run utility * run possibility\n\n- Optimal agents\n  - Maximizes the expected utility (on average)\n  - **Bounded**: only those agents that **can be implemented on machine m**\n\n- Task environment\n  - Predicate task specification: succeeds/fails\n  - A pair: environment, task specification\n    - the system's properties\n    - judging criterias\n  - Judging\n    - Pessimistic: all run must be succeeded\n    - Optimistic: a run is succeeded\n  - The probability of success\n    - Sum of all success runs\n  - Types\n    - Achivement: to the goal\n    - Maintenance: not to fail\n\n## Chapter 3 key notes\n\n- Architecture: modules & interaction between them\n\n- Symbolic Reasoning Agents: Modeling the world using symbols\n\n- Deductive Reasoning Agents:\n  - Theorem proving\n  - Find a possible action by\n    - Prove it works\n    - Prove NotDo(action) can not be proved\n\n- Agent oriented programming: using the intentional notions"},"collectionChildren":null},"__N_SSG":true}
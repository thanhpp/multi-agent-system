{"pageProps":{"note":{"id":"FlDl9gx2mBtFM41D123aX","title":"C2-IntelligentAgents","vault":{"fsPath":"vault"},"type":"note","desc":"","links":[{"from":{"fname":"root","vaultName":"vault"},"type":"backlink","position":{"start":{"line":19,"column":3,"offset":368},"end":{"line":19,"column":56,"offset":421},"indent":[]},"value":"C2-IntelligentAgents"},{"from":{"fname":"root","vaultName":"vault"},"type":"backlink","position":{"start":{"line":47,"column":3,"offset":1180},"end":{"line":47,"column":52,"offset":1229},"indent":[]},"value":"C2-IntelligentAgents"},{"from":{"fname":"C3-DeductiveReasoningAgents","vaultName":"vault"},"type":"backlink","position":{"start":{"line":34,"column":3,"offset":975},"end":{"line":34,"column":65,"offset":1037},"indent":[]},"value":"C2-IntelligentAgents"}],"anchors":{"autonomy":{"type":"header","text":"Autonomy","value":"autonomy","line":31,"column":0,"depth":1},"agents-and":{"type":"header","text":"Agents and","value":"agents-and","line":36,"column":0,"depth":1},"objects":{"type":"header","text":"Objects","value":"objects","line":38,"column":0,"depth":2},"expert-systems":{"type":"header","text":"Expert systems","value":"expert-systems","line":51,"column":0,"depth":2},"intelligent-agents-and-ai":{"type":"header","text":"Intelligent agents and AI","value":"intelligent-agents-and-ai","line":55,"column":0,"depth":2},"environment-properties":{"type":"header","text":"Environment Properties","value":"environment-properties","line":59,"column":0,"depth":1},"intelligent-agents":{"type":"header","text":"Intelligent agents","value":"intelligent-agents","line":76,"column":0,"depth":1},"reactive-environment-aware":{"type":"header","text":"Reactive (environment aware)","value":"reactive-environment-aware","line":78,"column":0,"depth":2},"pro-active":{"type":"header","text":"Pro-active","value":"pro-active","line":84,"column":0,"depth":2},"social-ability":{"type":"header","text":"Social ability","value":"social-ability","line":88,"column":0,"depth":2},"other-properties":{"type":"header","text":"Other properties","value":"other-properties","line":96,"column":0,"depth":2},"intentional-system":{"type":"header","text":"Intentional System","value":"intentional-system","line":103,"column":0,"depth":1},"abstract-architecture":{"type":"header","text":"Abstract architecture","value":"abstract-architecture","line":108,"column":0,"depth":1},"environments":{"type":"header","text":"Environments","value":"environments","line":119,"column":0,"depth":2},"agents":{"type":"header","text":"Agents","value":"agents","line":130,"column":0,"depth":2},"system":{"type":"header","text":"System","value":"system","line":135,"column":0,"depth":2},"intelligent-agent-properties":{"type":"header","text":"Intelligent agent properties","value":"intelligent-agent-properties","line":141,"column":0,"depth":1},"agents-with-states":{"type":"header","text":"Agents with States","value":"agents-with-states","line":149,"column":0,"depth":2},"task-for-agents":{"type":"header","text":"Task for Agents","value":"task-for-agents","line":164,"column":0,"depth":1},"utility-functions":{"type":"header","text":"Utility functions","value":"utility-functions","line":166,"column":0,"depth":2},"optimal-agents":{"type":"header","text":"Optimal agents","value":"optimal-agents","line":187,"column":0,"depth":2},"task-environment":{"type":"header","text":"Task environment","value":"task-environment","line":197,"column":0,"depth":2}},"fname":"C2-IntelligentAgents","updated":1639932292448,"created":1639841130136,"parent":"BnuhRJcMOGIp7ASYnzgfK","children":[],"data":{},"contentHash":"43506aa2c72d8918c113985ecf9c8174","custom":{}},"body":"<h1 id=\"c2-intelligentagents\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#c2-intelligentagents\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>C2-IntelligentAgents</h1>\n<ul>\n<li><a href=\"#autonomy\">Autonomy</a></li>\n<li><a href=\"#agents-and\">Agents and</a>\n<ul>\n<li><a href=\"#objects\">Objects</a></li>\n<li><a href=\"#expert-systems\">Expert systems</a></li>\n<li><a href=\"#intelligent-agents-and-ai\">Intelligent agents and AI</a></li>\n</ul>\n</li>\n<li><a href=\"#environment-properties\">Environment Properties</a></li>\n<li><a href=\"#intelligent-agents\">Intelligent agents</a>\n<ul>\n<li><a href=\"#reactive-environment-aware\">Reactive (environment aware)</a></li>\n<li><a href=\"#pro-active\">Pro-active</a></li>\n<li><a href=\"#social-ability\">Social ability</a></li>\n<li><a href=\"#other-properties\">Other properties</a></li>\n</ul>\n</li>\n<li><a href=\"#intentional-system\">Intentional System</a></li>\n<li><a href=\"#abstract-architecture\">Abstract architecture</a>\n<ul>\n<li><a href=\"#environments\">Environments</a></li>\n<li><a href=\"#agents\">Agents</a></li>\n<li><a href=\"#system\">System</a></li>\n</ul>\n</li>\n<li><a href=\"#intelligent-agent-properties\">Intelligent agent properties</a>\n<ul>\n<li><a href=\"#agents-with-states\">Agents with States</a></li>\n</ul>\n</li>\n<li><a href=\"#task-for-agents\">Task for Agents</a>\n<ul>\n<li><a href=\"#utility-functions\">Utility functions</a></li>\n<li><a href=\"#optimal-agents\">Optimal agents</a></li>\n<li><a href=\"#task-environment\">Task environment</a></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"autonomy\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#autonomy\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Autonomy</h1>\n<ul>\n<li>Tính tự trị\n<ul>\n<li>Decisions making</li>\n</ul>\n</li>\n<li>Adjustable: Decisions handed to a higher authority when this is benefical</li>\n</ul>\n<h1 id=\"agents-and\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#agents-and\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Agents and</h1>\n<h2 id=\"objects\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#objects\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Objects</h2>\n<ul>\n<li>\n<p>Agent = object + <strong>attitude</strong></p>\n</li>\n<li>\n<p>Object:</p>\n<ul>\n<li>States</li>\n<li>Message passing</li>\n<li>Methods (operations that may be performed on this state)</li>\n</ul>\n</li>\n<li>\n<p>Attitude</p>\n<ul>\n<li>Autonomous: Decide for themselves whether or not to follow other's requests</li>\n<li>Smart: Flexible (reactive, pro-active, social) behaviour</li>\n<li>Active: each agent has at least 1 thread of active control</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"expert-systems\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#expert-systems\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Expert systems</h2>\n<ul>\n<li>Def: \"expertise\" about some (abstract) domain of discourse (bàn luận)</li>\n<li>Agent is <strong>aware</strong> of the world</li>\n</ul>\n<h2 id=\"intelligent-agents-and-ai\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#intelligent-agents-and-ai\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Intelligent agents and AI</h2>\n<ul>\n<li>Agent can be built to operate in <strong>a limited domain</strong></li>\n<li>A useful agent is not needed to solve all the AI's problems</li>\n</ul>\n<h1 id=\"environment-properties\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#environment-properties\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Environment Properties</h1>\n<ul>\n<li>Observable: fully or partially\n<ul>\n<li>Fully: The agent can obtain complete, accurate, up-to-date information about the environment's state</li>\n</ul>\n</li>\n<li>Deterministic or non-deterministic\n<ul>\n<li>Deterministic: Any action has a single <strong>guaranteed effect</strong> (no uncertainty)</li>\n</ul>\n</li>\n<li>Static or dynamic\n<ul>\n<li>Static: Remain <strong>unchanged</strong> except by the agent's action</li>\n</ul>\n</li>\n<li>Discrete or continuous\n<ul>\n<li>Discrete: <strong>a fixed, finite number of actions</strong> and percepts in it</li>\n</ul>\n</li>\n<li>Episodic or non-episodic\n<ul>\n<li>Phân đoạn</li>\n<li>Episodic environment\n<ul>\n<li>The performance of agent is <strong>dependent on a number of discrete eptisodes</strong></li>\n<li>No linkages between different scenarios</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Real time\n<ul>\n<li><strong>Time</strong> plays a part in <strong>evaluating</strong> an agents performance</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"intelligent-agents\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#intelligent-agents\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Intelligent agents</h1>\n<h2 id=\"reactive-environment-aware\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#reactive-environment-aware\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Reactive (environment aware)</h2>\n<ul>\n<li>Phản ứng nhanh</li>\n<li>A reactive system is one that\n<ul>\n<li>Maintains an ongoing interaction with its environment</li>\n<li><strong>Responds to changes</strong> that occurs in it</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"pro-active\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#pro-active\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Pro-active</h2>\n<ul>\n<li>Chuyên nghiệp</li>\n<li>Generating and attempting to achieve goals</li>\n</ul>\n<h2 id=\"social-ability\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#social-ability\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Social ability</h2>\n<ul>\n<li>Taking <strong>others</strong> into account</li>\n<li>Cooperation: working <strong>together</strong> to achieve a <strong>shared goal</strong></li>\n<li>Coordination: Managing the <strong>interdependencies</strong> between activities (sharing resources)</li>\n<li>Negotiation: To reach <strong>agreements</strong> on matters of <strong>common interest</strong>\n<ul>\n<li>Offer</li>\n<li>Counter offer</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"other-properties\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#other-properties\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Other properties</h2>\n<ul>\n<li>Mobility: moving</li>\n<li>Rationality (hợp lý): Act to achieve goals</li>\n<li>Veracity (xác thực): know the communication failures</li>\n<li>Benevolence (nhân từ): to help or not to help</li>\n<li>Learning/Adaption</li>\n</ul>\n<h1 id=\"intentional-system\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#intentional-system\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Intentional System</h1>\n<ul>\n<li>Folk psychology:\n<ul>\n<li><strong>Human behaviour is predicted</strong> and explainend through the attribution of <strong>attitudes</strong>.</li>\n<li>Attitudes = intentional notions</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"abstract-architecture\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#abstract-architecture\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Abstract architecture</h1>\n<ul>\n<li>The world \n<ul>\n<li>Finite set E of discrete, instantaneous (tức thời) <strong>states</strong> \n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-17-09-25.png\"></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Agents have a set of <strong>possible actions</strong> to transform the state of the world\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-17-10-59.png\"></li>\n</ul>\n</li>\n<li>A <strong>run</strong> of an agent is a <strong>sequence</strong> of interleaved (xen kẽ) <em>world states and actions</em>\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-17-12-45.png\">  </li>\n<li>Runs can end with a state or an action\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-17-21-18.png\"></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"environments\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#environments\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Environments</h2>\n<ul>\n<li>Properties\n<ul>\n<li>History dependent</li>\n<li>Non-determistic</li>\n</ul>\n</li>\n<li>State transformer function: environment's behaviour\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-17-24-49.png\"></li>\n</ul>\n</li>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-17-45-14.png\">\n<ul>\n<li>E: set of states</li>\n<li>e[0]: initial state</li>\n<li>T: state transformer function</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"agents\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#agents\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Agents</h2>\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-17-47-19.png\">\n<ul>\n<li>Agent = function which maps <strong>runs to actions</strong></li>\n<li>Ag: the set of all agents</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"system\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#system\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>System</h2>\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-17-49-38.png\"></li>\n<li>A system = an agent + an environment</li>\n<li>Associate with a set of <strong>possible runs</strong></li>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-17-55-43.png\"></li>\n</ul>\n<h1 id=\"intelligent-agent-properties\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#intelligent-agent-properties\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Intelligent agent properties</h1>\n<ul>\n<li>Deliberative (chủ ý): Agent will reach a <strong>different decision</strong> when it reach the <strong>same state</strong> by <strong>different routes</strong> </li>\n<li>Purely reactive\n<ul>\n<li>Without history references</li>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-18-00-52.png\"> (state to actions)</li>\n<li>Reactive agent\n<ul>\n<li>Always do the <strong>same thing</strong> in the <strong>same state</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"agents-with-states\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#agents-with-states\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Agents with States</h2>\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-22-43-54.png\"></li>\n<li>Agent's internal <strong>data structure</strong>\n<ul>\n<li>Record information about the environment state &#x26; history</li>\n</ul>\n</li>\n<li><strong>See</strong>: observe the environment\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-22-44-54.png\"></li>\n<li>Output is a percept (nhận thức)</li>\n</ul>\n</li>\n<li><strong>Action</strong>: decision making\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-22-48-24.png\"></li>\n<li>Internal states -> actions</li>\n</ul>\n</li>\n<li><strong>Next</strong>: \n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-22-51-50.png\"></li>\n<li>Internal States + percept => new internal states</li>\n<li><strong>Updates</strong> the agent's view when it gets a <strong>new percept</strong></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"task-for-agents\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#task-for-agents\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Task for Agents</h1>\n<h2 id=\"utility-functions\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#utility-functions\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Utility functions</h2>\n<ul>\n<li><strong>Rewarding</strong> agent with the state it brings out</li>\n<li>A task specification\n<ul>\n<li>A real number (reward) with every environment state</li>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-22-56-27.png\"></li>\n</ul>\n</li>\n<li>Local utility functions\n<ul>\n<li>Assigning utilities to <strong>individual states</strong></li>\n<li>Difficult to specify a <strong>long term view</strong></li>\n<li><strong>Reinforcement</strong> learning: A <strong>discount</strong> for states later on</li>\n</ul>\n</li>\n<li>Sequential decision making\n<ul>\n<li>Utility gained depends on the route taken</li>\n</ul>\n</li>\n<li>Utilities over Runs\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-23-01-28.png\"></li>\n<li>Assign utility for runs</li>\n</ul>\n</li>\n<li>Expected utility\n<ul>\n<li>Probality that run <em>r</em> occurs when agent <em>Ag</em> is placed in the enviroment <em>Env</em>\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-23-04-15.png\"></li>\n</ul>\n</li>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-23-04-50.png\">\n<ul>\n<li>Utility of each run</li>\n<li>Possibility of each run</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"optimal-agents\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#optimal-agents\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Optimal agents</h2>\n<ul>\n<li>Maximizes expected utility\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-23-08-11.png\"></li>\n</ul>\n</li>\n<li>Do the best <strong>on average</strong></li>\n<li>Bounded optimal agents\n<ul>\n<li>Some agents <strong>can not be implemented</strong></li>\n<li>Include only those agents tthat can be implemented on <strong>machine m</strong>\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-23-11-13.png\"></li>\n</ul>\n</li>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-23-10-54.png\"></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"task-environment\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#task-environment\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Task environment</h2>\n<ul>\n<li>Predicate task specification: Assign 0/1 (true/false | succeed/failed) to a run\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-23-13-26.png\"></li>\n</ul>\n</li>\n<li>Task environment:\n<ul>\n<li>A pair <img src=\"/multi-agent-system/./assets/images/2021-12-19-23-14-41.png\">\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-23-14-17.png\"></li>\n<li>Environment</li>\n<li>Task specification</li>\n</ul>\n</li>\n<li>Specifies\n<ul>\n<li>The properties of <a href=\"#system\">the system</a> the agent will inhabit (occupy)</li>\n<li>The <strong>criteria</strong> by which an agent will be <strong>judged</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>A set of runs of agent <em>Ag</em> in environment <em>Env</em> that satisfy <em><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>ψ</mi></mrow><annotation encoding=\"application/x-tex\">\\psi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ψ</span></span></span></span></span></em>\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-23-23-52.png\"> </li>\n<li>Agent <em>Ag</em> succeeds in task environment <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>&#x3C;</mo><mi>E</mi><mi>n</mi><mi>v</mi><mo separator=\"true\">,</mo><mi>ψ</mi><mo>></mo></mrow><annotation encoding=\"application/x-tex\">&#x3C;Env, \\psi></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mrel\">&#x3C;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ψ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">></span></span></span></span></span>\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-23-27-12.png\"></li>\n<li>An agent succeeds if <strong>every run satisfies the specification of the agent</strong>\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-23-29-32.png\"></li>\n</ul>\n</li>\n<li>More optimistic: succeed = at least a successful run\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-23-29-18.png\"></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>The probability of success\n<ul>\n<li>Non-deterministic: the state transform function returns <strong>a set of possible states</strong></li>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-19-23-34-14.png\">\n<ul>\n<li>The sum of probabilities of every run that satisfy <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>ψ</mi></mrow><annotation encoding=\"application/x-tex\">\\psi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">ψ</span></span></span></span></span> when agent <em>Ag</em> is placed in environment <em>Env</em></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Types\n<ul>\n<li>Achievement: if the agent can <strong>force the environment</strong> into one of the goal states</li>\n<li>Maintenance: if the agent <strong>never forced into</strong> one of the fail states</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2 id=\"backlinks\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#backlinks\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Backlinks</h2>\n<ul>\n<li><a href=\"/multi-agent-system/notes/BnuhRJcMOGIp7ASYnzgfK\">Multi-Agent System</a></li>\n<li><a href=\"/multi-agent-system/notes/GscZd6gucdQM8ZPOjmJnM\">C3-DeductiveReasoningAgents</a></li>\n</ul>","noteIndex":{"id":"BnuhRJcMOGIp7ASYnzgfK","title":"Multi-Agent System","vault":{"fsPath":"vault"},"type":"note","desc":"","links":[{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C1-Introduction","position":{"start":{"line":4,"column":22,"offset":64},"end":{"line":4,"column":66,"offset":108},"indent":[]},"xvault":false,"to":{"fname":"C1-Introduction","anchorHeader":"multi-agent-system,1:#*"}},{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C2-IntelligentAgents","position":{"start":{"line":19,"column":3,"offset":368},"end":{"line":19,"column":56,"offset":421},"indent":[]},"xvault":false,"to":{"fname":"C2-IntelligentAgents","anchorHeader":"environment-properties,1:#*"}},{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C2-IntelligentAgents","position":{"start":{"line":47,"column":3,"offset":1180},"end":{"line":47,"column":52,"offset":1229},"indent":[]},"xvault":false,"to":{"fname":"C2-IntelligentAgents","anchorHeader":"agents-with-states,1:#*"}}],"anchors":{"công-nghệ-tác-tử":{"type":"header","text":"Công nghệ tác tử","value":"công-nghệ-tác-tử","line":7,"column":0,"depth":1},"chapter-1-key-notes":{"type":"header","text":"Chapter 1 key notes","value":"chapter-1-key-notes","line":9,"column":0,"depth":2},"chapter-2-key-notes":{"type":"header","text":"Chapter 2 key notes","value":"chapter-2-key-notes","line":12,"column":0,"depth":2},"chapter-3-key-notes":{"type":"header","text":"Chapter 3 key notes","value":"chapter-3-key-notes","line":81,"column":0,"depth":2}},"fname":"root","updated":1639971779311,"created":1639839870130,"parent":null,"children":["nyjsbqpAPM3WrEtJJFLmn","FlDl9gx2mBtFM41D123aX","GscZd6gucdQM8ZPOjmJnM"],"data":{},"contentHash":"0bed781d8c55b3ab9beed855964a880b","custom":{"nav_order":0,"permalink":"/"},"body":"# Công nghệ tác tử\n\n## Chapter 1 key notes\n- Multi-agent system ![[C1-Introduction#multi-agent-system,1:#*]]\n\n## Chapter 2 key notes\n- Agent ~ Autonomous ~ Making decisions\n  - What to perform?\n  - When to perform?\n\n- Agents\n  - Have attitude\n    - Autonomous\n    - Smart - flexible behaviours\n    - Active\n  - Environment awareness\n  - Operate in a limited domain\n\n- ![[C2-IntelligentAgents#environment-properties,1:#*]]\n\n- Intelligent agents\n  - Reactive\n    - Environment aware\n    - Responds to changes\n  - Pro-active (achieving goals)\n  - Social ability (working with others)\n\n- The behaviour of an agent can be predicted using its intention\n\n- Abstract architecture\n  - World has a finite set of states\n  - Agents have a set of possible actions\n  - A run: a sequence of actions and states\n\n- Notion\n  - Environment: states, initial states, transformer function\n  - Agent: runs -> action\n  - A system: \n    - a pair of an agent & an environment\n    - has a set of possible runs\n    - ![](./assets/images/2021-12-19-17-55-51.png) \n\n- Deliberative vs Purely reactive\n  - Deliberative: Making decisions Reactive agent\n    - Always do the **same thing** in the **same state**\n\n- ![[C2-IntelligentAgents#agents-with-states,1:#*]]\n\n- Utility function:\n  - Rewarding agents\n  - Locality: utility for each state, no long term view\n  - Reinforcement: a discount for states later on\n  - Sequential decision making: Utilities depend on the route\n  - Assign utilities for runs: long term view\n  - Expected utility: run utility * run possibility\n\n- Optimal agents\n  - Maximizes the expected utility (on average)\n  - **Bounded**: only those agents that **can be implemented on machine m**\n\n- Task environment\n  - Predicate task specification: succeeds/fails\n  - A pair: environment, task specification\n    - the system's properties\n    - judging criterias\n  - Judging\n    - Pessimistic: all run must be succeeded\n    - Optimistic: a run is succeeded\n  - The probability of success\n    - Sum of all success runs\n  - Types\n    - Achivement: to the goal\n    - Maintenance: not to fail\n\n## Chapter 3 key notes\n\n- Architecture: modules & interaction between them\n\n- Symbolic Reasoning Agents: Modeling the world using symbols\n\n- Deductive Reasoning Agents:\n  - Theorem proving\n  - Find a possible action by\n    - Prove it works\n    - Prove NotDo(action) can not be proved\n\n- Agent oriented programming: using the intentional notions"},"collectionChildren":null,"customHeadContent":null,"config":{"version":4,"useFMTitle":true,"useNoteTitleForLink":true,"mermaid":true,"useKatex":true,"dev":{"enablePreviewV2":true},"site":{"copyAssets":true,"siteHierarchies":["root"],"siteRootDir":"docs","usePrettyRefs":true,"title":"Dendron","description":"Personal knowledge space","siteLastModified":true,"gh_edit_branch":"main","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"assetsPrefix":"/multi-agent-system","siteUrl":"https://thanhpp.github.io","usePrettyLinks":true,"siteNotesDir":"notes","siteFaviconPath":"favicon.ico","gh_edit_link":true,"gh_edit_link_text":"Edit this page on GitHub","gh_root":"docs/","gh_edit_view_mode":"edit","writeStubs":true,"siteIndex":"root"},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false}},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true}}},"__N_SSG":true}
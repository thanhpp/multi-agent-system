{"pageProps":{"note":{"id":"GscZd6gucdQM8ZPOjmJnM","title":"C3-DeductiveReasoningAgents","vault":{"fsPath":"vault"},"type":"note","desc":"","links":[{"type":"wiki","from":{"fname":"C3-DeductiveReasoningAgents","id":"GscZd6gucdQM8ZPOjmJnM","vaultName":"vault"},"value":"C2-IntelligentAgents","alias":"Agents with States","position":{"start":{"line":34,"column":3,"offset":975},"end":{"line":34,"column":65,"offset":1037},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"C2-IntelligentAgents","anchorHeader":"agents-with-states"}}],"anchors":{"agent-architecture":{"type":"header","text":"Agent architecture","value":"agent-architecture","line":10,"column":0,"depth":1},"symbolic-reasoning-agents":{"type":"header","text":"Symbolic Reasoning Agents","value":"symbolic-reasoning-agents","line":24,"column":0,"depth":2},"deductive-reasoning-agents":{"type":"header","text":"Deductive Reasoning Agents","value":"deductive-reasoning-agents","line":34,"column":0,"depth":2},"agent-oriented-programming":{"type":"header","text":"Agent oriented programming","value":"agent-oriented-programming","line":53,"column":0,"depth":1},"agent0":{"type":"header","text":"Agent0","value":"agent0","line":57,"column":0,"depth":2},"placa":{"type":"header","text":"PLACA","value":"placa","line":93,"column":0,"depth":2},"metatem":{"type":"header","text":"MetateM","value":"metatem","line":97,"column":0,"depth":2}},"fname":"C3-DeductiveReasoningAgents","updated":1639973329538,"created":1639969491690,"parent":"BnuhRJcMOGIp7ASYnzgfK","children":[],"data":{},"contentHash":"da11e0be140ad3eb0d82ce27bb1f5056","custom":{}},"body":"<h1 id=\"c3-deductivereasoningagents\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#c3-deductivereasoningagents\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>C3-DeductiveReasoningAgents</h1>\n<blockquote>\n<p>Tác tử có khả năng suy luận</p>\n</blockquote>\n<h1 id=\"agent-architecture\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#agent-architecture\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Agent architecture</h1>\n<ul>\n<li>\n<p>Architecture</p>\n<ul>\n<li>A set of software/hardware/modules</li>\n<li>Data &#x26; control flow (interactions) between modules</li>\n</ul>\n</li>\n<li>\n<p>Classes</p>\n<ul>\n<li>Symbolic Reasoning Agents\n<ul>\n<li>Make decisions via <strong>symbol manipulation</strong></li>\n<li>Agents use explicit logical reasoning</li>\n</ul>\n</li>\n<li>Reactive Agents\n<ul>\n<li>Learning</li>\n<li>Based on the environment</li>\n</ul>\n</li>\n<li>Hybrid agent</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"symbolic-reasoning-agents\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#symbolic-reasoning-agents\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Symbolic Reasoning Agents</h2>\n<ul>\n<li>A particular type of <strong>knowledge-based system</strong></li>\n<li>Deliberative (Có chủ đích) agent\n<ul>\n<li>A symbolic model of the world</li>\n<li>Makes decisions</li>\n<li>Issues\n<ul>\n<li>The transduction problem: identifying objects (limited)</li>\n<li>The representation problem: represent objects (large amount of information)</li>\n<li>Symbol manipulation</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"deductive-reasoning-agents\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#deductive-reasoning-agents\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Deductive Reasoning Agents</h2>\n<ul>\n<li>Making decisions based on theorem proving</li>\n<li>Notations\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-20-10-31-08.png\"></li>\n<li>Database: internal states</li>\n<li>Theory is used to prove</li>\n</ul>\n</li>\n<li><a href=\"/multi-agent-system/notes/FlDl9gx2mBtFM41D123aX#agents-with-states\">Agents with States</a>\n<ul>\n<li>Next function:\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-20-10-32-42.png\"></li>\n</ul>\n</li>\n<li>Action function:\n<ul>\n<li>Find an action explicitly <strong>prescribed</strong>\n<ul>\n<li>Returns the action if it is proved</li>\n</ul>\n</li>\n<li>Find an action not excluded\n<ul>\n<li><img src=\"/multi-agent-system/./assets/images/2021-12-20-10-38-02.png\"></li>\n<li>Returns the action if NotDo(action) can not be proved</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Problems &#x26; Solutions\n<ul>\n<li>Convert inputs to perceptions (weaken the logic; use symbolic, non-logical representations)</li>\n<li>Shift the emphasis of reasoning from run time to <strong>design time</strong></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"agent-oriented-programming\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#agent-oriented-programming\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Agent oriented programming</h1>\n<ul>\n<li>Keys:\n<ul>\n<li>Programming in terms of intentional (chủ đích) notions</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"agent0\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#agent0\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Agent0</h2>\n<ul>\n<li>\n<p>Agent:</p>\n<ul>\n<li>a set of capabilities</li>\n<li>a set of initial beliefs</li>\n<li>a set of initial commitments</li>\n<li>a set of <strong>commitment rules</strong></li>\n</ul>\n</li>\n<li>\n<p>Commitment rule</p>\n<ul>\n<li>components\n<ul>\n<li>a message condition</li>\n<li>a mental condition</li>\n<li>an action</li>\n</ul>\n</li>\n<li>paraphrase\n<ul>\n<li>if i receive a message from <strong>agent</strong> \n<ul>\n<li>Which requests me to do <strong>action</strong> at <strong>time</strong></li>\n</ul>\n</li>\n<li>I believe that\n<ul>\n<li><strong>agent</strong> is a friend</li>\n<li>I <strong>can</strong> do the action</li>\n<li>at <strong>time</strong>, I am <strong>not commited</strong> to doing any other action</li>\n</ul>\n</li>\n<li>Then I commit to doing <strong>action</strong> at <strong>time</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>\n<p>Decision cycle</p>\n<ul>\n<li>the message condition => The messages the agent has received</li>\n<li>the mental condition => The beliefs of the agent</li>\n<li>if the <strong>rule fires</strong>, the agent becomes commited to the action</li>\n</ul>\n</li>\n<li>\n<p>Action types</p>\n<ul>\n<li>Private</li>\n<li>Communicative</li>\n</ul>\n</li>\n<li>\n<p>Message types</p>\n<ul>\n<li>Requests (commit)</li>\n<li>Unrequests (refrain)</li>\n<li>Inform (pass the information)</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"placa\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#placa\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>PLACA</h2>\n<ul>\n<li>Plan and communicate requests for action via <strong>high-level goals</strong></li>\n<li>In terms of <strong>mental change rules</strong></li>\n</ul>\n<h2 id=\"metatem\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#metatem\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>MetateM</h2>\n<ul>\n<li>Each agent is given a <strong>temporal logic specification</strong> of the behaviour it should exhibit</li>\n<li>Modal operators: How the truth of propositions changes over time\n<ul>\n<li>World = discrete states</li>\n<li>1 single history, a number of possible futures</li>\n</ul>\n</li>\n</ul>","noteIndex":{"id":"BnuhRJcMOGIp7ASYnzgfK","title":"Multi-Agent System","vault":{"fsPath":"vault"},"type":"note","desc":"","links":[{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C1-Introduction","position":{"start":{"line":4,"column":22,"offset":64},"end":{"line":4,"column":66,"offset":108},"indent":[]},"xvault":false,"to":{"fname":"C1-Introduction","anchorHeader":"multi-agent-system,1:#*"}},{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C2-IntelligentAgents","position":{"start":{"line":19,"column":3,"offset":368},"end":{"line":19,"column":56,"offset":421},"indent":[]},"xvault":false,"to":{"fname":"C2-IntelligentAgents","anchorHeader":"environment-properties,1:#*"}},{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C2-IntelligentAgents","position":{"start":{"line":47,"column":3,"offset":1180},"end":{"line":47,"column":52,"offset":1229},"indent":[]},"xvault":false,"to":{"fname":"C2-IntelligentAgents","anchorHeader":"agents-with-states,1:#*"}}],"anchors":{"công-nghệ-tác-tử":{"type":"header","text":"Công nghệ tác tử","value":"công-nghệ-tác-tử","line":7,"column":0,"depth":1},"chapter-1-key-notes":{"type":"header","text":"Chapter 1 key notes","value":"chapter-1-key-notes","line":9,"column":0,"depth":2},"chapter-2-key-notes":{"type":"header","text":"Chapter 2 key notes","value":"chapter-2-key-notes","line":12,"column":0,"depth":2},"chapter-3-key-notes":{"type":"header","text":"Chapter 3 key notes","value":"chapter-3-key-notes","line":81,"column":0,"depth":2}},"fname":"root","updated":1639971779311,"created":1639839870130,"parent":null,"children":["nyjsbqpAPM3WrEtJJFLmn","FlDl9gx2mBtFM41D123aX","GscZd6gucdQM8ZPOjmJnM"],"data":{},"contentHash":"0bed781d8c55b3ab9beed855964a880b","custom":{"nav_order":0,"permalink":"/"},"body":"# Công nghệ tác tử\n\n## Chapter 1 key notes\n- Multi-agent system ![[C1-Introduction#multi-agent-system,1:#*]]\n\n## Chapter 2 key notes\n- Agent ~ Autonomous ~ Making decisions\n  - What to perform?\n  - When to perform?\n\n- Agents\n  - Have attitude\n    - Autonomous\n    - Smart - flexible behaviours\n    - Active\n  - Environment awareness\n  - Operate in a limited domain\n\n- ![[C2-IntelligentAgents#environment-properties,1:#*]]\n\n- Intelligent agents\n  - Reactive\n    - Environment aware\n    - Responds to changes\n  - Pro-active (achieving goals)\n  - Social ability (working with others)\n\n- The behaviour of an agent can be predicted using its intention\n\n- Abstract architecture\n  - World has a finite set of states\n  - Agents have a set of possible actions\n  - A run: a sequence of actions and states\n\n- Notion\n  - Environment: states, initial states, transformer function\n  - Agent: runs -> action\n  - A system: \n    - a pair of an agent & an environment\n    - has a set of possible runs\n    - ![](./assets/images/2021-12-19-17-55-51.png) \n\n- Deliberative vs Purely reactive\n  - Deliberative: Making decisions Reactive agent\n    - Always do the **same thing** in the **same state**\n\n- ![[C2-IntelligentAgents#agents-with-states,1:#*]]\n\n- Utility function:\n  - Rewarding agents\n  - Locality: utility for each state, no long term view\n  - Reinforcement: a discount for states later on\n  - Sequential decision making: Utilities depend on the route\n  - Assign utilities for runs: long term view\n  - Expected utility: run utility * run possibility\n\n- Optimal agents\n  - Maximizes the expected utility (on average)\n  - **Bounded**: only those agents that **can be implemented on machine m**\n\n- Task environment\n  - Predicate task specification: succeeds/fails\n  - A pair: environment, task specification\n    - the system's properties\n    - judging criterias\n  - Judging\n    - Pessimistic: all run must be succeeded\n    - Optimistic: a run is succeeded\n  - The probability of success\n    - Sum of all success runs\n  - Types\n    - Achivement: to the goal\n    - Maintenance: not to fail\n\n## Chapter 3 key notes\n\n- Architecture: modules & interaction between them\n\n- Symbolic Reasoning Agents: Modeling the world using symbols\n\n- Deductive Reasoning Agents:\n  - Theorem proving\n  - Find a possible action by\n    - Prove it works\n    - Prove NotDo(action) can not be proved\n\n- Agent oriented programming: using the intentional notions"},"collectionChildren":null,"customHeadContent":null,"config":{"version":4,"useFMTitle":true,"useNoteTitleForLink":true,"mermaid":true,"useKatex":true,"dev":{"enablePreviewV2":true},"site":{"copyAssets":true,"siteHierarchies":["root"],"siteRootDir":"docs","usePrettyRefs":true,"title":"Dendron","description":"Personal knowledge space","siteLastModified":true,"gh_edit_branch":"main","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"assetsPrefix":"/multi-agent-system","siteUrl":"https://thanhpp.github.io","usePrettyLinks":true,"siteNotesDir":"notes","siteFaviconPath":"favicon.ico","gh_edit_link":true,"gh_edit_link_text":"Edit this page on GitHub","gh_root":"docs/","gh_edit_view_mode":"edit","writeStubs":true,"siteIndex":"root"},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false}},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true}}},"__N_SSG":true}
<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><title>Multi-Agent System</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="Multi-Agent System"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://thanhpp.github.io/multi-agent-system/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="12/18/2021"/><meta property="article:modified_time" content="12/20/2021"/><link rel="canonical" href="https://thanhpp.github.io/multi-agent-system/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/multi-agent-system/_next/static/css/8ce458e8b675715c.css" as="style"/><link rel="stylesheet" href="/multi-agent-system/_next/static/css/8ce458e8b675715c.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/multi-agent-system/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/multi-agent-system/_next/static/chunks/webpack-4b02ecd94e394484.js" defer=""></script><script src="/multi-agent-system/_next/static/chunks/framework-dc33c0b5493501f0.js" defer=""></script><script src="/multi-agent-system/_next/static/chunks/main-4871c3831fd32318.js" defer=""></script><script src="/multi-agent-system/_next/static/chunks/pages/_app-219df97d3f231fab.js" defer=""></script><script src="/multi-agent-system/_next/static/chunks/155-55f0622fbbf90797.js" defer=""></script><script src="/multi-agent-system/_next/static/chunks/pages/index-06cc0dd469b223f3.js" defer=""></script><script src="/multi-agent-system/_next/static/lSWqs0cT-BkIgtf6sLCuG/_buildManifest.js" defer=""></script><script src="/multi-agent-system/_next/static/lSWqs0cT-BkIgtf6sLCuG/_ssgManifest.js" defer=""></script><script src="/multi-agent-system/_next/static/lSWqs0cT-BkIgtf6sLCuG/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div class="ant-col"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"></div><div style="margin-left:4px;display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout site-layout" style="margin-top:64px"><section class="ant-layout site-layout" style="flex-direction:row"><section class="ant-layout site-layout-sidebar" style="flex:0 0 auto;width:calc((100% - 992px) / 2 + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></section><section class="ant-layout side-layout-main" style="max-width:1200px;display:initial"><main class="ant-layout-content main-content" role="main" style="padding:0 24px"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="multi-agent-system"><a aria-hidden="true" class="anchor-heading" href="#multi-agent-system"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Multi-Agent System</h1>
<h1 id="công-nghệ-tác-tử"><a aria-hidden="true" class="anchor-heading" href="#công-nghệ-tác-tử"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Công nghệ tác tử</h1>
<h2 id="chapter-1-key-notes"><a aria-hidden="true" class="anchor-heading" href="#chapter-1-key-notes"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Chapter 1 key notes</h2>
<ul>
<li>Multi-agent system <p></p><div class="portal-container">
<div class="portal-head">
<div class="portal-backlink">
<div class="portal-title">From <span class="portal-text-title">C1-Introduction</span></div>
<a href="/multi-agent-system/notes/nyjsbqpAPM3WrEtJJFLmn" class="portal-arrow">Go to text <span class="right-arrow">→</span></a>
</div>
</div>
<div id="portal-parent-anchor" class="portal-parent" markdown="1">
<div class="portal-parent-fader-top"></div>
<div class="portal-parent-fader-bottom"></div><ul>
<li>Consists of <strong>a number of agents</strong>
<ul>
<li>Each agent has different goal and motivation</li>
<li>Ability to cooperate, coordinate, negotiate</li>
</ul>
</li>
</ul>
</div></div><p></p></li>
</ul>
<h2 id="chapter-2-key-notes"><a aria-hidden="true" class="anchor-heading" href="#chapter-2-key-notes"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Chapter 2 key notes</h2>
<ul>
<li>
<p>Agent ~ Autonomous ~ Making decisions</p>
<ul>
<li>What to perform?</li>
<li>When to perform?</li>
</ul>
</li>
<li>
<p>Agents</p>
<ul>
<li>Have attitude
<ul>
<li>Autonomous</li>
<li>Smart - flexible behaviours</li>
<li>Active</li>
</ul>
</li>
<li>Environment awareness</li>
<li>Operate in a limited domain</li>
</ul>
</li>
<li>
<p></p><p></p><div class="portal-container">
<div class="portal-head">
<div class="portal-backlink">
<div class="portal-title">From <span class="portal-text-title">C2-IntelligentAgents</span></div>
<a href="/multi-agent-system/notes/FlDl9gx2mBtFM41D123aX" class="portal-arrow">Go to text <span class="right-arrow">→</span></a>
</div>
</div>
<div id="portal-parent-anchor" class="portal-parent" markdown="1">
<div class="portal-parent-fader-top"></div>
<div class="portal-parent-fader-bottom"></div><ul>
<li>Observable: fully or partially
<ul>
<li>Fully: The agent can obtain complete, accurate, up-to-date information about the environment's state</li>
</ul>
</li>
<li>Deterministic or non-deterministic
<ul>
<li>Deterministic: Any action has a single <strong>guaranteed effect</strong> (no uncertainty)</li>
</ul>
</li>
<li>Static or dynamic
<ul>
<li>Static: Remain <strong>unchanged</strong> except by the agent's action</li>
</ul>
</li>
<li>Discrete or continuous
<ul>
<li>Discrete: <strong>a fixed, finite number of actions</strong> and percepts in it</li>
</ul>
</li>
<li>Episodic or non-episodic
<ul>
<li>Phân đoạn</li>
<li>Episodic environment
<ul>
<li>The performance of agent is <strong>dependent on a number of discrete eptisodes</strong></li>
<li>No linkages between different scenarios</li>
</ul>
</li>
</ul>
</li>
<li>Real time
<ul>
<li><strong>Time</strong> plays a part in <strong>evaluating</strong> an agents performance</li>
</ul>
</li>
</ul>
</div></div><p></p><p></p>
</li>
<li>
<p>Intelligent agents</p>
<ul>
<li>Reactive
<ul>
<li>Environment aware</li>
<li>Responds to changes</li>
</ul>
</li>
<li>Pro-active (achieving goals)</li>
<li>Social ability (working with others)</li>
</ul>
</li>
<li>
<p>The behaviour of an agent can be predicted using its intention</p>
</li>
<li>
<p>Abstract architecture</p>
<ul>
<li>World has a finite set of states</li>
<li>Agents have a set of possible actions</li>
<li>A run: a sequence of actions and states</li>
</ul>
</li>
<li>
<p>Notion</p>
<ul>
<li>Environment: states, initial states, transformer function</li>
<li>Agent: runs -> action</li>
<li>A system: 
<ul>
<li>a pair of an agent &#x26; an environment</li>
<li>has a set of possible runs</li>
<li><img src="/multi-agent-system/./assets/images/2021-12-19-17-55-51.png"> </li>
</ul>
</li>
</ul>
</li>
<li>
<p>Deliberative vs Purely reactive</p>
<ul>
<li>Deliberative: Making decisions Reactive agent
<ul>
<li>Always do the <strong>same thing</strong> in the <strong>same state</strong></li>
</ul>
</li>
</ul>
</li>
<li>
<p></p><p></p><div class="portal-container">
<div class="portal-head">
<div class="portal-backlink">
<div class="portal-title">From <span class="portal-text-title">C2-IntelligentAgents</span></div>
<a href="/multi-agent-system/notes/FlDl9gx2mBtFM41D123aX" class="portal-arrow">Go to text <span class="right-arrow">→</span></a>
</div>
</div>
<div id="portal-parent-anchor" class="portal-parent" markdown="1">
<div class="portal-parent-fader-top"></div>
<div class="portal-parent-fader-bottom"></div><ul>
<li><img src="/multi-agent-system/./assets/images/2021-12-19-22-43-54.png"></li>
<li>Agent's internal <strong>data structure</strong>
<ul>
<li>Record information about the environment state &#x26; history</li>
</ul>
</li>
<li><strong>See</strong>: observe the environment
<ul>
<li><img src="/multi-agent-system/./assets/images/2021-12-19-22-44-54.png"></li>
<li>Output is a percept (nhận thức)</li>
</ul>
</li>
<li><strong>Action</strong>: decision making
<ul>
<li><img src="/multi-agent-system/./assets/images/2021-12-19-22-48-24.png"></li>
<li>Internal states -> actions</li>
</ul>
</li>
<li><strong>Next</strong>: 
<ul>
<li><img src="/multi-agent-system/./assets/images/2021-12-19-22-51-50.png"></li>
<li>Internal States + percept => new internal states</li>
<li><strong>Updates</strong> the agent's view when it gets a <strong>new percept</strong></li>
</ul>
</li>
</ul>
</div></div><p></p><p></p>
</li>
<li>
<p>Utility function:</p>
<ul>
<li>Rewarding agents</li>
<li>Locality: utility for each state, no long term view</li>
<li>Reinforcement: a discount for states later on</li>
<li>Sequential decision making: Utilities depend on the route</li>
<li>Assign utilities for runs: long term view</li>
<li>Expected utility: run utility * run possibility</li>
</ul>
</li>
<li>
<p>Optimal agents</p>
<ul>
<li>Maximizes the expected utility (on average)</li>
<li><strong>Bounded</strong>: only those agents that <strong>can be implemented on machine m</strong></li>
</ul>
</li>
<li>
<p>Task environment</p>
<ul>
<li>Predicate task specification: succeeds/fails</li>
<li>A pair: environment, task specification
<ul>
<li>the system's properties</li>
<li>judging criterias</li>
</ul>
</li>
<li>Judging
<ul>
<li>Pessimistic: all run must be succeeded</li>
<li>Optimistic: a run is succeeded</li>
</ul>
</li>
<li>The probability of success
<ul>
<li>Sum of all success runs</li>
</ul>
</li>
<li>Types
<ul>
<li>Achivement: to the goal</li>
<li>Maintenance: not to fail</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="chapter-3-key-notes"><a aria-hidden="true" class="anchor-heading" href="#chapter-3-key-notes"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Chapter 3 key notes</h2>
<ul>
<li>
<p>Architecture: modules &#x26; interaction between them</p>
</li>
<li>
<p>Symbolic Reasoning Agents: Modeling the world using symbols</p>
</li>
<li>
<p>Deductive Reasoning Agents:</p>
<ul>
<li>Theorem proving</li>
<li>Find a possible action by
<ul>
<li>Prove it works</li>
<li>Prove NotDo(action) can not be proved</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Agent oriented programming: using the intentional notions</p>
</li>
</ul>
<hr>
<h2 id="children"><a aria-hidden="true" class="anchor-heading" href="#children"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Children</h2>
<ol>
<li><a href="/multi-agent-system/notes/nyjsbqpAPM3WrEtJJFLmn">C1-Introduction</a></li>
<li><a href="/multi-agent-system/notes/FlDl9gx2mBtFM41D123aX">C2-IntelligentAgents</a></li>
<li><a href="/multi-agent-system/notes/GscZd6gucdQM8ZPOjmJnM">C3-DeductiveReasoningAgents</a></li>
</ol></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#công-nghệ-tác-tử" title="Công nghệ tác tử">Công nghệ tác tử</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#chapter-1-key-notes" title="Chapter 1 key notes">Chapter 1 key notes</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#chapter-2-key-notes" title="Chapter 2 key notes">Chapter 2 key notes</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#chapter-3-key-notes" title="Chapter 3 key notes">Chapter 3 key notes</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#children" title="Children">Children</a></div></div></div></div></div></div></div></div></div></main><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></section></section></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"body":"\u003ch1 id=\"multi-agent-system\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#multi-agent-system\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eMulti-Agent System\u003c/h1\u003e\n\u003ch1 id=\"công-nghệ-tác-tử\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#công-nghệ-tác-tử\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eCông nghệ tác tử\u003c/h1\u003e\n\u003ch2 id=\"chapter-1-key-notes\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#chapter-1-key-notes\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eChapter 1 key notes\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eMulti-agent system \u003cp\u003e\u003c/p\u003e\u003cdiv class=\"portal-container\"\u003e\n\u003cdiv class=\"portal-head\"\u003e\n\u003cdiv class=\"portal-backlink\"\u003e\n\u003cdiv class=\"portal-title\"\u003eFrom \u003cspan class=\"portal-text-title\"\u003eC1-Introduction\u003c/span\u003e\u003c/div\u003e\n\u003ca href=\"/multi-agent-system/notes/nyjsbqpAPM3WrEtJJFLmn\" class=\"portal-arrow\"\u003eGo to text \u003cspan class=\"right-arrow\"\u003e→\u003c/span\u003e\u003c/a\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv id=\"portal-parent-anchor\" class=\"portal-parent\" markdown=\"1\"\u003e\n\u003cdiv class=\"portal-parent-fader-top\"\u003e\u003c/div\u003e\n\u003cdiv class=\"portal-parent-fader-bottom\"\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003eConsists of \u003cstrong\u003ea number of agents\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eEach agent has different goal and motivation\u003c/li\u003e\n\u003cli\u003eAbility to cooperate, coordinate, negotiate\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e\u003c/div\u003e\u003cp\u003e\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"chapter-2-key-notes\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#chapter-2-key-notes\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eChapter 2 key notes\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eAgent ~ Autonomous ~ Making decisions\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhat to perform?\u003c/li\u003e\n\u003cli\u003eWhen to perform?\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAgents\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHave attitude\n\u003cul\u003e\n\u003cli\u003eAutonomous\u003c/li\u003e\n\u003cli\u003eSmart - flexible behaviours\u003c/li\u003e\n\u003cli\u003eActive\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eEnvironment awareness\u003c/li\u003e\n\u003cli\u003eOperate in a limited domain\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cdiv class=\"portal-container\"\u003e\n\u003cdiv class=\"portal-head\"\u003e\n\u003cdiv class=\"portal-backlink\"\u003e\n\u003cdiv class=\"portal-title\"\u003eFrom \u003cspan class=\"portal-text-title\"\u003eC2-IntelligentAgents\u003c/span\u003e\u003c/div\u003e\n\u003ca href=\"/multi-agent-system/notes/FlDl9gx2mBtFM41D123aX\" class=\"portal-arrow\"\u003eGo to text \u003cspan class=\"right-arrow\"\u003e→\u003c/span\u003e\u003c/a\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv id=\"portal-parent-anchor\" class=\"portal-parent\" markdown=\"1\"\u003e\n\u003cdiv class=\"portal-parent-fader-top\"\u003e\u003c/div\u003e\n\u003cdiv class=\"portal-parent-fader-bottom\"\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003eObservable: fully or partially\n\u003cul\u003e\n\u003cli\u003eFully: The agent can obtain complete, accurate, up-to-date information about the environment's state\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eDeterministic or non-deterministic\n\u003cul\u003e\n\u003cli\u003eDeterministic: Any action has a single \u003cstrong\u003eguaranteed effect\u003c/strong\u003e (no uncertainty)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eStatic or dynamic\n\u003cul\u003e\n\u003cli\u003eStatic: Remain \u003cstrong\u003eunchanged\u003c/strong\u003e except by the agent's action\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eDiscrete or continuous\n\u003cul\u003e\n\u003cli\u003eDiscrete: \u003cstrong\u003ea fixed, finite number of actions\u003c/strong\u003e and percepts in it\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eEpisodic or non-episodic\n\u003cul\u003e\n\u003cli\u003ePhân đoạn\u003c/li\u003e\n\u003cli\u003eEpisodic environment\n\u003cul\u003e\n\u003cli\u003eThe performance of agent is \u003cstrong\u003edependent on a number of discrete eptisodes\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eNo linkages between different scenarios\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eReal time\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTime\u003c/strong\u003e plays a part in \u003cstrong\u003eevaluating\u003c/strong\u003e an agents performance\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e\u003c/div\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIntelligent agents\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eReactive\n\u003cul\u003e\n\u003cli\u003eEnvironment aware\u003c/li\u003e\n\u003cli\u003eResponds to changes\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ePro-active (achieving goals)\u003c/li\u003e\n\u003cli\u003eSocial ability (working with others)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe behaviour of an agent can be predicted using its intention\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAbstract architecture\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWorld has a finite set of states\u003c/li\u003e\n\u003cli\u003eAgents have a set of possible actions\u003c/li\u003e\n\u003cli\u003eA run: a sequence of actions and states\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNotion\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEnvironment: states, initial states, transformer function\u003c/li\u003e\n\u003cli\u003eAgent: runs -\u003e action\u003c/li\u003e\n\u003cli\u003eA system: \n\u003cul\u003e\n\u003cli\u003ea pair of an agent \u0026#x26; an environment\u003c/li\u003e\n\u003cli\u003ehas a set of possible runs\u003c/li\u003e\n\u003cli\u003e\u003cimg src=\"/multi-agent-system/./assets/images/2021-12-19-17-55-51.png\"\u003e \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDeliberative vs Purely reactive\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDeliberative: Making decisions Reactive agent\n\u003cul\u003e\n\u003cli\u003eAlways do the \u003cstrong\u003esame thing\u003c/strong\u003e in the \u003cstrong\u003esame state\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cdiv class=\"portal-container\"\u003e\n\u003cdiv class=\"portal-head\"\u003e\n\u003cdiv class=\"portal-backlink\"\u003e\n\u003cdiv class=\"portal-title\"\u003eFrom \u003cspan class=\"portal-text-title\"\u003eC2-IntelligentAgents\u003c/span\u003e\u003c/div\u003e\n\u003ca href=\"/multi-agent-system/notes/FlDl9gx2mBtFM41D123aX\" class=\"portal-arrow\"\u003eGo to text \u003cspan class=\"right-arrow\"\u003e→\u003c/span\u003e\u003c/a\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv id=\"portal-parent-anchor\" class=\"portal-parent\" markdown=\"1\"\u003e\n\u003cdiv class=\"portal-parent-fader-top\"\u003e\u003c/div\u003e\n\u003cdiv class=\"portal-parent-fader-bottom\"\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003cimg src=\"/multi-agent-system/./assets/images/2021-12-19-22-43-54.png\"\u003e\u003c/li\u003e\n\u003cli\u003eAgent's internal \u003cstrong\u003edata structure\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eRecord information about the environment state \u0026#x26; history\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSee\u003c/strong\u003e: observe the environment\n\u003cul\u003e\n\u003cli\u003e\u003cimg src=\"/multi-agent-system/./assets/images/2021-12-19-22-44-54.png\"\u003e\u003c/li\u003e\n\u003cli\u003eOutput is a percept (nhận thức)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAction\u003c/strong\u003e: decision making\n\u003cul\u003e\n\u003cli\u003e\u003cimg src=\"/multi-agent-system/./assets/images/2021-12-19-22-48-24.png\"\u003e\u003c/li\u003e\n\u003cli\u003eInternal states -\u003e actions\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNext\u003c/strong\u003e: \n\u003cul\u003e\n\u003cli\u003e\u003cimg src=\"/multi-agent-system/./assets/images/2021-12-19-22-51-50.png\"\u003e\u003c/li\u003e\n\u003cli\u003eInternal States + percept =\u003e new internal states\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUpdates\u003c/strong\u003e the agent's view when it gets a \u003cstrong\u003enew percept\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e\u003c/div\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUtility function:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRewarding agents\u003c/li\u003e\n\u003cli\u003eLocality: utility for each state, no long term view\u003c/li\u003e\n\u003cli\u003eReinforcement: a discount for states later on\u003c/li\u003e\n\u003cli\u003eSequential decision making: Utilities depend on the route\u003c/li\u003e\n\u003cli\u003eAssign utilities for runs: long term view\u003c/li\u003e\n\u003cli\u003eExpected utility: run utility * run possibility\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eOptimal agents\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMaximizes the expected utility (on average)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBounded\u003c/strong\u003e: only those agents that \u003cstrong\u003ecan be implemented on machine m\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eTask environment\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePredicate task specification: succeeds/fails\u003c/li\u003e\n\u003cli\u003eA pair: environment, task specification\n\u003cul\u003e\n\u003cli\u003ethe system's properties\u003c/li\u003e\n\u003cli\u003ejudging criterias\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eJudging\n\u003cul\u003e\n\u003cli\u003ePessimistic: all run must be succeeded\u003c/li\u003e\n\u003cli\u003eOptimistic: a run is succeeded\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eThe probability of success\n\u003cul\u003e\n\u003cli\u003eSum of all success runs\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eTypes\n\u003cul\u003e\n\u003cli\u003eAchivement: to the goal\u003c/li\u003e\n\u003cli\u003eMaintenance: not to fail\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"chapter-3-key-notes\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#chapter-3-key-notes\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eChapter 3 key notes\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eArchitecture: modules \u0026#x26; interaction between them\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSymbolic Reasoning Agents: Modeling the world using symbols\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDeductive Reasoning Agents:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTheorem proving\u003c/li\u003e\n\u003cli\u003eFind a possible action by\n\u003cul\u003e\n\u003cli\u003eProve it works\u003c/li\u003e\n\u003cli\u003eProve NotDo(action) can not be proved\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAgent oriented programming: using the intentional notions\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"children\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#children\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eChildren\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"/multi-agent-system/notes/nyjsbqpAPM3WrEtJJFLmn\"\u003eC1-Introduction\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/multi-agent-system/notes/FlDl9gx2mBtFM41D123aX\"\u003eC2-IntelligentAgents\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/multi-agent-system/notes/GscZd6gucdQM8ZPOjmJnM\"\u003eC3-DeductiveReasoningAgents\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e","note":{"id":"BnuhRJcMOGIp7ASYnzgfK","title":"Multi-Agent System","vault":{"fsPath":"vault"},"type":"note","desc":"","links":[{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C1-Introduction","position":{"start":{"line":4,"column":22,"offset":64},"end":{"line":4,"column":66,"offset":108},"indent":[]},"xvault":false,"to":{"fname":"C1-Introduction","anchorHeader":"multi-agent-system,1:#*"}},{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C2-IntelligentAgents","position":{"start":{"line":19,"column":3,"offset":368},"end":{"line":19,"column":56,"offset":421},"indent":[]},"xvault":false,"to":{"fname":"C2-IntelligentAgents","anchorHeader":"environment-properties,1:#*"}},{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C2-IntelligentAgents","position":{"start":{"line":47,"column":3,"offset":1180},"end":{"line":47,"column":52,"offset":1229},"indent":[]},"xvault":false,"to":{"fname":"C2-IntelligentAgents","anchorHeader":"agents-with-states,1:#*"}}],"anchors":{"công-nghệ-tác-tử":{"type":"header","text":"Công nghệ tác tử","value":"công-nghệ-tác-tử","line":7,"column":0,"depth":1},"chapter-1-key-notes":{"type":"header","text":"Chapter 1 key notes","value":"chapter-1-key-notes","line":9,"column":0,"depth":2},"chapter-2-key-notes":{"type":"header","text":"Chapter 2 key notes","value":"chapter-2-key-notes","line":12,"column":0,"depth":2},"chapter-3-key-notes":{"type":"header","text":"Chapter 3 key notes","value":"chapter-3-key-notes","line":81,"column":0,"depth":2}},"fname":"root","updated":1639971779311,"created":1639839870130,"parent":null,"children":["nyjsbqpAPM3WrEtJJFLmn","FlDl9gx2mBtFM41D123aX","GscZd6gucdQM8ZPOjmJnM"],"data":{},"contentHash":"0bed781d8c55b3ab9beed855964a880b","custom":{"nav_order":0,"permalink":"/"},"body":"# Công nghệ tác tử\n\n## Chapter 1 key notes\n- Multi-agent system ![[C1-Introduction#multi-agent-system,1:#*]]\n\n## Chapter 2 key notes\n- Agent ~ Autonomous ~ Making decisions\n  - What to perform?\n  - When to perform?\n\n- Agents\n  - Have attitude\n    - Autonomous\n    - Smart - flexible behaviours\n    - Active\n  - Environment awareness\n  - Operate in a limited domain\n\n- ![[C2-IntelligentAgents#environment-properties,1:#*]]\n\n- Intelligent agents\n  - Reactive\n    - Environment aware\n    - Responds to changes\n  - Pro-active (achieving goals)\n  - Social ability (working with others)\n\n- The behaviour of an agent can be predicted using its intention\n\n- Abstract architecture\n  - World has a finite set of states\n  - Agents have a set of possible actions\n  - A run: a sequence of actions and states\n\n- Notion\n  - Environment: states, initial states, transformer function\n  - Agent: runs -\u003e action\n  - A system: \n    - a pair of an agent \u0026 an environment\n    - has a set of possible runs\n    - ![](./assets/images/2021-12-19-17-55-51.png) \n\n- Deliberative vs Purely reactive\n  - Deliberative: Making decisions Reactive agent\n    - Always do the **same thing** in the **same state**\n\n- ![[C2-IntelligentAgents#agents-with-states,1:#*]]\n\n- Utility function:\n  - Rewarding agents\n  - Locality: utility for each state, no long term view\n  - Reinforcement: a discount for states later on\n  - Sequential decision making: Utilities depend on the route\n  - Assign utilities for runs: long term view\n  - Expected utility: run utility * run possibility\n\n- Optimal agents\n  - Maximizes the expected utility (on average)\n  - **Bounded**: only those agents that **can be implemented on machine m**\n\n- Task environment\n  - Predicate task specification: succeeds/fails\n  - A pair: environment, task specification\n    - the system's properties\n    - judging criterias\n  - Judging\n    - Pessimistic: all run must be succeeded\n    - Optimistic: a run is succeeded\n  - The probability of success\n    - Sum of all success runs\n  - Types\n    - Achivement: to the goal\n    - Maintenance: not to fail\n\n## Chapter 3 key notes\n\n- Architecture: modules \u0026 interaction between them\n\n- Symbolic Reasoning Agents: Modeling the world using symbols\n\n- Deductive Reasoning Agents:\n  - Theorem proving\n  - Find a possible action by\n    - Prove it works\n    - Prove NotDo(action) can not be proved\n\n- Agent oriented programming: using the intentional notions"},"config":{"version":4,"useFMTitle":true,"useNoteTitleForLink":true,"mermaid":true,"useKatex":true,"dev":{"enablePreviewV2":true},"site":{"copyAssets":true,"siteHierarchies":["root"],"siteRootDir":"docs","usePrettyRefs":true,"title":"Dendron","description":"Personal knowledge space","siteLastModified":true,"gh_edit_branch":"main","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"assetsPrefix":"/multi-agent-system","siteUrl":"https://thanhpp.github.io","usePrettyLinks":true,"siteNotesDir":"notes","siteFaviconPath":"favicon.ico","gh_edit_link":true,"gh_edit_link_text":"Edit this page on GitHub","gh_root":"docs/","gh_edit_view_mode":"edit","writeStubs":true,"siteIndex":"root"},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false}},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true}},"customHeadContent":null,"noteIndex":{"id":"BnuhRJcMOGIp7ASYnzgfK","title":"Multi-Agent System","vault":{"fsPath":"vault"},"type":"note","desc":"","links":[{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C1-Introduction","position":{"start":{"line":4,"column":22,"offset":64},"end":{"line":4,"column":66,"offset":108},"indent":[]},"xvault":false,"to":{"fname":"C1-Introduction","anchorHeader":"multi-agent-system,1:#*"}},{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C2-IntelligentAgents","position":{"start":{"line":19,"column":3,"offset":368},"end":{"line":19,"column":56,"offset":421},"indent":[]},"xvault":false,"to":{"fname":"C2-IntelligentAgents","anchorHeader":"environment-properties,1:#*"}},{"type":"ref","from":{"fname":"root","id":"BnuhRJcMOGIp7ASYnzgfK","vaultName":"vault"},"value":"C2-IntelligentAgents","position":{"start":{"line":47,"column":3,"offset":1180},"end":{"line":47,"column":52,"offset":1229},"indent":[]},"xvault":false,"to":{"fname":"C2-IntelligentAgents","anchorHeader":"agents-with-states,1:#*"}}],"anchors":{"công-nghệ-tác-tử":{"type":"header","text":"Công nghệ tác tử","value":"công-nghệ-tác-tử","line":7,"column":0,"depth":1},"chapter-1-key-notes":{"type":"header","text":"Chapter 1 key notes","value":"chapter-1-key-notes","line":9,"column":0,"depth":2},"chapter-2-key-notes":{"type":"header","text":"Chapter 2 key notes","value":"chapter-2-key-notes","line":12,"column":0,"depth":2},"chapter-3-key-notes":{"type":"header","text":"Chapter 3 key notes","value":"chapter-3-key-notes","line":81,"column":0,"depth":2}},"fname":"root","updated":1639971779311,"created":1639839870130,"parent":null,"children":["nyjsbqpAPM3WrEtJJFLmn","FlDl9gx2mBtFM41D123aX","GscZd6gucdQM8ZPOjmJnM"],"data":{},"contentHash":"0bed781d8c55b3ab9beed855964a880b","custom":{"nav_order":0,"permalink":"/"},"body":"# Công nghệ tác tử\n\n## Chapter 1 key notes\n- Multi-agent system ![[C1-Introduction#multi-agent-system,1:#*]]\n\n## Chapter 2 key notes\n- Agent ~ Autonomous ~ Making decisions\n  - What to perform?\n  - When to perform?\n\n- Agents\n  - Have attitude\n    - Autonomous\n    - Smart - flexible behaviours\n    - Active\n  - Environment awareness\n  - Operate in a limited domain\n\n- ![[C2-IntelligentAgents#environment-properties,1:#*]]\n\n- Intelligent agents\n  - Reactive\n    - Environment aware\n    - Responds to changes\n  - Pro-active (achieving goals)\n  - Social ability (working with others)\n\n- The behaviour of an agent can be predicted using its intention\n\n- Abstract architecture\n  - World has a finite set of states\n  - Agents have a set of possible actions\n  - A run: a sequence of actions and states\n\n- Notion\n  - Environment: states, initial states, transformer function\n  - Agent: runs -\u003e action\n  - A system: \n    - a pair of an agent \u0026 an environment\n    - has a set of possible runs\n    - ![](./assets/images/2021-12-19-17-55-51.png) \n\n- Deliberative vs Purely reactive\n  - Deliberative: Making decisions Reactive agent\n    - Always do the **same thing** in the **same state**\n\n- ![[C2-IntelligentAgents#agents-with-states,1:#*]]\n\n- Utility function:\n  - Rewarding agents\n  - Locality: utility for each state, no long term view\n  - Reinforcement: a discount for states later on\n  - Sequential decision making: Utilities depend on the route\n  - Assign utilities for runs: long term view\n  - Expected utility: run utility * run possibility\n\n- Optimal agents\n  - Maximizes the expected utility (on average)\n  - **Bounded**: only those agents that **can be implemented on machine m**\n\n- Task environment\n  - Predicate task specification: succeeds/fails\n  - A pair: environment, task specification\n    - the system's properties\n    - judging criterias\n  - Judging\n    - Pessimistic: all run must be succeeded\n    - Optimistic: a run is succeeded\n  - The probability of success\n    - Sum of all success runs\n  - Types\n    - Achivement: to the goal\n    - Maintenance: not to fail\n\n## Chapter 3 key notes\n\n- Architecture: modules \u0026 interaction between them\n\n- Symbolic Reasoning Agents: Modeling the world using symbols\n\n- Deductive Reasoning Agents:\n  - Theorem proving\n  - Find a possible action by\n    - Prove it works\n    - Prove NotDo(action) can not be proved\n\n- Agent oriented programming: using the intentional notions"},"collectionChildren":null},"__N_SSG":true},"page":"/","query":{},"buildId":"lSWqs0cT-BkIgtf6sLCuG","assetPrefix":"/multi-agent-system","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>